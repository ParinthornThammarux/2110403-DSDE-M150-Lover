{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "318c14da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ef8ca9",
   "metadata": {},
   "source": [
    "## Inspect Dataframe\n",
    "\n",
    "def inspect_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe72ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_dataframe(df):\n",
    "    # ทำสำเนาเพื่อความปลอดภัย (กันการแก้ไขของเดิมโดยไม่ตั้งใจ)\n",
    "    df_safe = df.copy()\n",
    "\n",
    "    print(f\"Loaded {len(df_safe):,} rows × {len(df_safe.columns):,} columns\")\n",
    "    display(df_safe.head())\n",
    "\n",
    "    print(\"\\nDataFrame info:\")\n",
    "    df_safe.info()\n",
    "\n",
    "    print(\"\\nMissing values per column:\")\n",
    "    print(df_safe.isna().sum())\n",
    "    print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7480a8e2",
   "metadata": {},
   "source": [
    "## Remove row that province not in bangkok\n",
    "\n",
    "filter_bangkok(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ac41552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_bangkok(df):\n",
    "    \"\"\"ลบแถวที่ province ไม่ใช่กรุงเทพฯ / Bangkok และแสดง before–after แบบ 1 บรรทัด\"\"\"\n",
    "    print(f\"before: {len(df)}\", end=\"  ->  \")\n",
    "    df = df[df['province'].astype(str).str.contains(r'กรุงเทพ|Bangkok', case=False, na=False)]\n",
    "    print(f\"after: {len(df)}\")\n",
    "    print(\"----------------------------------------\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e94c97",
   "metadata": {},
   "source": [
    "## drop_rows_with_nan\n",
    "\n",
    "drop_rows_with_nan(df, cols, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d065177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows_with_nan(df, cols, inplace=False):\n",
    "    \"\"\"\n",
    "    Drop rows that have NaN in any column listed in `cols`.\n",
    "    - df: pandas DataFrame\n",
    "    - cols: list-like of column names to check for NaN\n",
    "    - inplace: if True, modify df in-place and return it; otherwise return a new DataFrame\n",
    "    \"\"\"\n",
    "    cols = list(cols)\n",
    "    missing_cols = [c for c in cols if c not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Columns not found in DataFrame: {missing_cols}\")\n",
    "\n",
    "    before = len(df)\n",
    "    result = df.dropna(subset=cols)\n",
    "    after = len(result)\n",
    "    print(f\"Dropped {before - after} rows with NaN in {cols} (before: {before}, after: {after})\")\n",
    "    print(\"----------------------------------------\")\n",
    "\n",
    "    if inplace:\n",
    "        # replace contents of original DataFrame\n",
    "        df.drop(df.index, inplace=True)\n",
    "        for col in result.columns:\n",
    "            df[col] = result[col]\n",
    "        return df\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bb91f1",
   "metadata": {},
   "source": [
    "## Drop Columns\n",
    "\n",
    "drop_columns(df, cols, inplace=False, ignore_missing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4321ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df, cols, inplace=False, ignore_missing=False):\n",
    "    \"\"\"\n",
    "    Drop columns by name.\n",
    "    - df: pandas DataFrame\n",
    "    - cols: list-like of column names to drop\n",
    "    - inplace: if True, modify df in-place and return it; otherwise return a new DataFrame\n",
    "    - ignore_missing: if True, silently ignore names not present in df; otherwise raise KeyError\n",
    "    \"\"\"\n",
    "    cols = list(cols)\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        if ignore_missing:\n",
    "            cols = [c for c in cols if c in df.columns]\n",
    "        else:\n",
    "            raise KeyError(f\"Columns not found: {missing}\")\n",
    "\n",
    "    if inplace:\n",
    "        df.drop(columns=cols, inplace=True)\n",
    "        print(f\"Dropped columns (in-place): {cols}\")\n",
    "        return df\n",
    "    result = df.drop(columns=cols)\n",
    "    print(f\"Dropped columns (returned new df): {cols}\")\n",
    "    print(\"----------------------------------------\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d016ec",
   "metadata": {},
   "source": [
    "## One hot encoder\n",
    "\n",
    "one_hot_encode(df, cols, method='sklearn', drop_first=False, inplace=False, return_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6216042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_sklearn(df, cols, drop_first=False, inplace=False, return_encoder=False, verbose=True):\n",
    "    \"\"\"\n",
    "    One-hot encode `cols` using sklearn.OneHotEncoder (compatible with old/new sklearn).\n",
    "    Logs actions if verbose=True.\n",
    "    - df: pandas DataFrame\n",
    "    - cols: list-like of column names to encode\n",
    "    - drop_first: if True drop first level (use drop='first' in OneHotEncoder)\n",
    "    - inplace: if True, replace contents of df and return it; otherwise return a new DataFrame\n",
    "    - return_encoder: if True return (result_df, encoder)\n",
    "    - verbose: if True print logs\n",
    "    \"\"\"\n",
    "    cols = list(cols)\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Columns not found: {missing}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"One-hot encoding columns: {cols}\")\n",
    "        print(f\"drop_first={drop_first}, inplace={inplace}, return_encoder={return_encoder}\")\n",
    "\n",
    "    enc_kwargs = {\"drop\": \"first\" if drop_first else None, \"handle_unknown\": \"ignore\"}\n",
    "    # instantiate encoder with compatibility for different sklearn versions\n",
    "    try:\n",
    "        enc = OneHotEncoder(sparse_output=False, **enc_kwargs)\n",
    "        api = \"sparse_output\"\n",
    "    except TypeError:\n",
    "        enc = OneHotEncoder(sparse=False, **enc_kwargs)\n",
    "        api = \"sparse\"\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Using OneHotEncoder API variant: {api}\")\n",
    "\n",
    "    arr = enc.fit_transform(df[cols])\n",
    "    new_cols = list(enc.get_feature_names_out(cols))\n",
    "    if verbose:\n",
    "        print(f\"Generated {len(new_cols)} columns, first 10: {new_cols[:10]}\")\n",
    "\n",
    "    df_ohe = pd.DataFrame(arr, index=df.index, columns=new_cols)\n",
    "    before_shape = df.shape\n",
    "    result = pd.concat([df.drop(columns=cols), df_ohe], axis=1)\n",
    "    after_shape = result.shape\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Shape before: {before_shape} -> after: {after_shape}\")\n",
    "        print(\"----------------------------------------\")\n",
    "\n",
    "    if inplace:\n",
    "        # replace contents of original DataFrame while keeping same object\n",
    "        df.drop(df.index, inplace=True)\n",
    "        for c in result.columns:\n",
    "            df[c] = result[c]\n",
    "        if verbose:\n",
    "            print(\"Replaced original DataFrame contents (in-place).\")\n",
    "        if return_encoder:\n",
    "            return df, enc\n",
    "        return df\n",
    "\n",
    "    if return_encoder:\n",
    "        return result, enc\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5948602",
   "metadata": {},
   "source": [
    "## Fill NaN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1041e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(df, cols, fills, inplace=False, verbose=True):\n",
    "    \"\"\"Fill NaN for cols using corresponding fills (cols and fills must match length).\"\"\"\n",
    "    if len(cols) != len(fills): raise ValueError(\"cols and fills must have same length\")\n",
    "    res = df if inplace else df.copy()\n",
    "    for c, f in zip(cols, fills):\n",
    "        if c not in res.columns:\n",
    "            if verbose: print(f\"⚠ '{c}' not found — skip\")\n",
    "            print(\"----------------------------------------\")\n",
    "            continue\n",
    "        if isinstance(f, dict) and not f or f is None:\n",
    "            val = \"Not define\"\n",
    "        else:\n",
    "            val = f\n",
    "        before = res[c].isna().sum()\n",
    "        res[c] = res[c].fillna(val)\n",
    "        if verbose:\n",
    "            filled = before - int(res[c].isna().sum())\n",
    "            print(f\"✔ {c}: filled {filled} with {repr(val)}\")\n",
    "            print(\"----------------------------------------\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffabc28d",
   "metadata": {},
   "source": [
    "## Parse date time\n",
    "\n",
    "safe_parse_datetime(df, col, fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85048a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_parse_datetime(df, col, fmt):\n",
    "    df[col] = pd.to_datetime(df[col], format=fmt, errors='coerce')\n",
    "    before = len(df)\n",
    "    df = df.dropna(subset=[col])\n",
    "    after = len(df)\n",
    "    print(f\"{col}: before {before} -> after {after}\")\n",
    "    print(\"----------------------------------------\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273544a0",
   "metadata": {},
   "source": [
    "## Eliminate Outliner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39c5ddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_outliers(df, cols=\"all_numeric\", method=\"iqr_cap\",\n",
    "                       factor=1.5, inplace=False, print_info=True):\n",
    "    \"\"\"\n",
    "    Remove or cap outliers using the IQR method.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - cols: list-like of column names, or \"all_numeric\" to apply on all numeric columns\n",
    "    - method: \"iqr_cap\" = truncate values, \"iqr_remove\" = remove rows\n",
    "    - factor: IQR multiplier (default 1.5)\n",
    "    - inplace: modify df in-place if True\n",
    "    - print_info: print summary for each column\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with outliers handled\n",
    "    \"\"\"\n",
    "\n",
    "    if not inplace:\n",
    "        df = df.copy()\n",
    "\n",
    "    # Automatically select numeric columns\n",
    "    if cols == \"all_numeric\":\n",
    "        cols = df.select_dtypes(include=\"number\").columns.tolist()\n",
    "\n",
    "    else:\n",
    "        cols = list(cols)\n",
    "\n",
    "    # Check existence\n",
    "    for col in cols:\n",
    "        if col not in df.columns:\n",
    "            raise KeyError(f\"Column '{col}' not found in DataFrame.\")\n",
    "\n",
    "    # Process each column\n",
    "    for col in cols:\n",
    "        if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "            if print_info:\n",
    "                print(f\"Skipping non-numeric column: {col}\")\n",
    "            continue\n",
    "\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower = Q1 - factor * IQR\n",
    "        upper = Q3 + factor * IQR\n",
    "\n",
    "        if method == \"iqr_cap\":\n",
    "            df[col] = df[col].clip(lower, upper)\n",
    "\n",
    "        elif method == \"iqr_remove\":\n",
    "            df = df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"method must be 'iqr_cap' or 'iqr_remove'\")\n",
    "\n",
    "        if print_info:\n",
    "            print(f\"[{col}]\")\n",
    "            print(f\"  Q1 = {Q1:.4f}, Q3 = {Q3:.4f}, IQR = {IQR:.4f}\")\n",
    "            print(f\"  lower = {lower:.4f}, upper = {upper:.4f}\")\n",
    "            print(f\"  method = {method}\")\n",
    "            print(\"----------------------------------------------------\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0ca16c",
   "metadata": {},
   "source": [
    "## call Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf2f7804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "path = Path(\"./bangkok_traffy.csv\")\n",
    "if not path.exists():\n",
    "    raise FileNotFoundError(f\"{path} not found in {Path.cwd()}\")\n",
    "\n",
    "df_raw = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f562a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 787,026 rows × 16 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>type</th>\n",
       "      <th>organization</th>\n",
       "      <th>comment</th>\n",
       "      <th>photo</th>\n",
       "      <th>photo_after</th>\n",
       "      <th>coords</th>\n",
       "      <th>address</th>\n",
       "      <th>subdistrict</th>\n",
       "      <th>district</th>\n",
       "      <th>province</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>state</th>\n",
       "      <th>star</th>\n",
       "      <th>count_reopen</th>\n",
       "      <th>last_activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-FYJTFP</td>\n",
       "      <td>{ความสะอาด}</td>\n",
       "      <td>เขตบางซื่อ</td>\n",
       "      <td>ขยะเยอะ</td>\n",
       "      <td>https://storage.googleapis.com/traffy_public_b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.53084,13.81865</td>\n",
       "      <td>12/14 ถนน กรุงเทพ- นนทบุรี แขวง บางซื่อ เขตบาง...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>2021-09-03 12:51:09.453003+00</td>\n",
       "      <td>เสร็จสิ้น</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-04 15:34:14.609206+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-CGPMUN</td>\n",
       "      <td>{น้ำท่วม,ร้องเรียน}</td>\n",
       "      <td>เขตประเวศ,ฝ่ายโยธา เขตประเวศ</td>\n",
       "      <td>น้ำท่วมเวลาฝนตกและทะลุเข้าบ้านเดือดร้อนมากทุกๆ...</td>\n",
       "      <td>https://storage.googleapis.com/traffy_public_b...</td>\n",
       "      <td>https://storage.googleapis.com/traffy_public_b...</td>\n",
       "      <td>100.66709,13.67891</td>\n",
       "      <td>189 เฉลิมพระเกียรติ ร.9 แขวง หนองบอน เขต ประเว...</td>\n",
       "      <td>หนองบอน</td>\n",
       "      <td>ประเวศ</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>2021-09-19 14:56:08.924992+00</td>\n",
       "      <td>เสร็จสิ้น</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-21 08:21:09.532782+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-7XATFA</td>\n",
       "      <td>{สะพาน}</td>\n",
       "      <td>เขตสาทร</td>\n",
       "      <td>สะพานลอยปรับปรุงไม่เสร็จตามกำหนด\\nปากซอย สาทร12</td>\n",
       "      <td>https://storage.googleapis.com/traffy_public_b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.52649,13.72060</td>\n",
       "      <td>191/1 ถนน สาทรเหนือ แขวง สีลม เขตบางรัก กรุงเท...</td>\n",
       "      <td>ยานนาวา</td>\n",
       "      <td>สาทร</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>2021-09-26 05:03:52.594898+00</td>\n",
       "      <td>เสร็จสิ้น</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-06 01:17:12.272904+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-9U2NJT</td>\n",
       "      <td>{น้ำท่วม}</td>\n",
       "      <td>เขตบางซื่อ,ฝ่ายโยธา เขตบางซื่อ</td>\n",
       "      <td>น้ำท่วม</td>\n",
       "      <td>https://storage.googleapis.com/traffy_public_b...</td>\n",
       "      <td>https://storage.googleapis.com/traffy_public_b...</td>\n",
       "      <td>100.53099,13.81853</td>\n",
       "      <td>12/14 ถนน กรุงเทพ- นนทบุรี แขวง บางซื่อ เขตบาง...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>2021-10-14 10:45:27.713884+00</td>\n",
       "      <td>เสร็จสิ้น</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-08 08:35:43.784519+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-DVEWYM</td>\n",
       "      <td>{น้ำท่วม,ถนน}</td>\n",
       "      <td>เขตลาดพร้าว,ฝ่ายโยธา เขตลาดพร้าว</td>\n",
       "      <td>ซอยลาดพร้าววังหิน 75 ถนนลาดพร้าววังหิน แขวงลาด...</td>\n",
       "      <td>https://storage.googleapis.com/traffy_public_b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.59165,13.82280</td>\n",
       "      <td>702 ถ. ลาดพร้าววังหิน แขวงลาดพร้าว เขตลาดพร้าว...</td>\n",
       "      <td>ลาดพร้าว</td>\n",
       "      <td>ลาดพร้าว</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>2021-12-09 12:29:08.408763+00</td>\n",
       "      <td>เสร็จสิ้น</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-08-12 07:18:44.884945+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticket_id                 type                      organization  \\\n",
       "0  2021-FYJTFP          {ความสะอาด}                        เขตบางซื่อ   \n",
       "1  2021-CGPMUN  {น้ำท่วม,ร้องเรียน}      เขตประเวศ,ฝ่ายโยธา เขตประเวศ   \n",
       "2  2021-7XATFA              {สะพาน}                           เขตสาทร   \n",
       "3  2021-9U2NJT            {น้ำท่วม}    เขตบางซื่อ,ฝ่ายโยธา เขตบางซื่อ   \n",
       "4  2021-DVEWYM        {น้ำท่วม,ถนน}  เขตลาดพร้าว,ฝ่ายโยธา เขตลาดพร้าว   \n",
       "\n",
       "                                             comment  \\\n",
       "0                                            ขยะเยอะ   \n",
       "1  น้ำท่วมเวลาฝนตกและทะลุเข้าบ้านเดือดร้อนมากทุกๆ...   \n",
       "2    สะพานลอยปรับปรุงไม่เสร็จตามกำหนด\\nปากซอย สาทร12   \n",
       "3                                            น้ำท่วม   \n",
       "4  ซอยลาดพร้าววังหิน 75 ถนนลาดพร้าววังหิน แขวงลาด...   \n",
       "\n",
       "                                               photo  \\\n",
       "0  https://storage.googleapis.com/traffy_public_b...   \n",
       "1  https://storage.googleapis.com/traffy_public_b...   \n",
       "2  https://storage.googleapis.com/traffy_public_b...   \n",
       "3  https://storage.googleapis.com/traffy_public_b...   \n",
       "4  https://storage.googleapis.com/traffy_public_b...   \n",
       "\n",
       "                                         photo_after              coords  \\\n",
       "0                                                NaN  100.53084,13.81865   \n",
       "1  https://storage.googleapis.com/traffy_public_b...  100.66709,13.67891   \n",
       "2                                                NaN  100.52649,13.72060   \n",
       "3  https://storage.googleapis.com/traffy_public_b...  100.53099,13.81853   \n",
       "4                                                NaN  100.59165,13.82280   \n",
       "\n",
       "                                             address subdistrict  district  \\\n",
       "0  12/14 ถนน กรุงเทพ- นนทบุรี แขวง บางซื่อ เขตบาง...         NaN       NaN   \n",
       "1  189 เฉลิมพระเกียรติ ร.9 แขวง หนองบอน เขต ประเว...     หนองบอน    ประเวศ   \n",
       "2  191/1 ถนน สาทรเหนือ แขวง สีลม เขตบางรัก กรุงเท...     ยานนาวา      สาทร   \n",
       "3  12/14 ถนน กรุงเทพ- นนทบุรี แขวง บางซื่อ เขตบาง...         NaN       NaN   \n",
       "4  702 ถ. ลาดพร้าววังหิน แขวงลาดพร้าว เขตลาดพร้าว...    ลาดพร้าว  ลาดพร้าว   \n",
       "\n",
       "        province                      timestamp      state  star  \\\n",
       "0  กรุงเทพมหานคร  2021-09-03 12:51:09.453003+00  เสร็จสิ้น   NaN   \n",
       "1  กรุงเทพมหานคร  2021-09-19 14:56:08.924992+00  เสร็จสิ้น   4.0   \n",
       "2  กรุงเทพมหานคร  2021-09-26 05:03:52.594898+00  เสร็จสิ้น   NaN   \n",
       "3  กรุงเทพมหานคร  2021-10-14 10:45:27.713884+00  เสร็จสิ้น   NaN   \n",
       "4  กรุงเทพมหานคร  2021-12-09 12:29:08.408763+00  เสร็จสิ้น   5.0   \n",
       "\n",
       "   count_reopen                  last_activity  \n",
       "0             0  2022-06-04 15:34:14.609206+00  \n",
       "1             0  2022-06-21 08:21:09.532782+00  \n",
       "2             0  2022-06-06 01:17:12.272904+00  \n",
       "3             0  2022-09-08 08:35:43.784519+00  \n",
       "4             0  2022-08-12 07:18:44.884945+00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 787026 entries, 0 to 787025\n",
      "Data columns (total 16 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   ticket_id      778254 non-null  object \n",
      " 1   type           786929 non-null  object \n",
      " 2   organization   786455 non-null  object \n",
      " 3   comment        778254 non-null  object \n",
      " 4   photo          786911 non-null  object \n",
      " 5   photo_after    641309 non-null  object \n",
      " 6   coords         787026 non-null  object \n",
      " 7   address        778254 non-null  object \n",
      " 8   subdistrict    786460 non-null  object \n",
      " 9   district       786465 non-null  object \n",
      " 10  province       786831 non-null  object \n",
      " 11  timestamp      787026 non-null  object \n",
      " 12  state          787026 non-null  object \n",
      " 13  star           274097 non-null  float64\n",
      " 14  count_reopen   787026 non-null  int64  \n",
      " 15  last_activity  787026 non-null  object \n",
      "dtypes: float64(1), int64(1), object(14)\n",
      "memory usage: 96.1+ MB\n",
      "\n",
      "Missing values per column:\n",
      "ticket_id          8772\n",
      "type                 97\n",
      "organization        571\n",
      "comment            8772\n",
      "photo               115\n",
      "photo_after      145717\n",
      "coords                0\n",
      "address            8772\n",
      "subdistrict         566\n",
      "district            561\n",
      "province            195\n",
      "timestamp             0\n",
      "state                 0\n",
      "star             512929\n",
      "count_reopen          0\n",
      "last_activity         0\n",
      "dtype: int64\n",
      "----------------------------------------\n",
      "Removed 8771 duplicate ticket_id rows (kept last).\n",
      "----------------------------------------------------\n",
      "before: 787026  ->  after: 785662\n",
      "----------------------------------------\n",
      "Dropped 50 rows with NaN in ['district', 'subdistrict'] (before: 785662, after: 785612)\n",
      "----------------------------------------\n",
      "drop_columns size before (785612, 16)\n",
      "Dropped columns (returned new df): ['photo', 'photo_after', 'ticket_id']\n",
      "----------------------------------------\n",
      "drop_columns size after (785612, 13)\n",
      "----------------------------------------------------\n",
      "One-hot encoding columns: ['state', 'star']\n",
      "drop_first=False, inplace=False, return_encoder=False\n",
      "Using OneHotEncoder API variant: sparse_output\n",
      "Generated 9 columns, first 10: ['state_กำลังดำเนินการ', 'state_รอรับเรื่อง', 'state_เสร็จสิ้น', 'star_1.0', 'star_2.0', 'star_3.0', 'star_4.0', 'star_5.0', 'star_nan']\n",
      "Shape before: (785612, 13) -> after: (785612, 20)\n",
      "----------------------------------------\n",
      "Dropped columns (returned new df): ['star_nan']\n",
      "----------------------------------------\n",
      "✔ comment: filled 8700 with 'ไม่มีคำอธิบาย'\n",
      "----------------------------------------\n",
      "✔ organization: filled 117 with 'ไม่ระบุหน่วยงาน'\n",
      "----------------------------------------\n",
      "✔ type: filled 97 with 'ไม่ระบุ'\n",
      "----------------------------------------\n",
      "timestamp: before 785612 -> after 785611\n",
      "----------------------------------------\n",
      "last_activity: before 785611 -> after 785610\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df = df_raw.copy()  # work on a copy to keep raw data intact\n",
    "\n",
    "# 0.) inspect\n",
    "inspect_dataframe(df)\n",
    "\n",
    "# 1.) remove duplicates ID by keep last\n",
    "df2 = df.drop_duplicates(subset='ticket_id', keep='last')\n",
    "print(f\"Removed {len(df) - len(df2)} duplicate ticket_id rows (kept last).\")\n",
    "print(\"----------------------------------------------------\")\n",
    "\n",
    "# 2.) filter bangkok in province\n",
    "df = filter_bangkok(df)\n",
    "\n",
    "# 3.) drop rows with nan\n",
    "df = drop_rows_with_nan(df, [\"district\", \"subdistrict\"])\n",
    "\n",
    "# 4.) drop columns that not use\n",
    "print(\"drop_columns size before\", df.shape)\n",
    "df = drop_columns(df, [\"photo\",\"photo_after\",\"ticket_id\"])\n",
    "print(\"drop_columns size after\", df.shape)\n",
    "print(\"----------------------------------------------------\")\n",
    "\n",
    "# 5.1) One hot\n",
    "df = one_hot_encode_sklearn(df, ['state','star'])\n",
    "df = drop_columns(df, [\"star_nan\"])\n",
    "#? df = one_hot_encode_sklearn(df, [\"organization\"])\n",
    "\n",
    "# ?5.2) One hot of type\n",
    "# df['type'] = (\n",
    "#     df['type']\n",
    "#     .str.replace(r'[\\{\\}]', '', regex=True)\n",
    "#     .str.split(',')\n",
    "# )\n",
    "\n",
    "# 6.) fill missing value with \"text\"\n",
    "fill_missing_values(df, \n",
    "                    [\"comment\",\"organization\",\"type\"], \n",
    "                    [\"ไม่มีคำอธิบาย\",\"ไม่ระบุหน่วยงาน\",\"ไม่ระบุ\"])\n",
    "\n",
    "# 7.) split coords to lon and lat\n",
    "df[['lon','lat']] = df['coords'].str.split(',', expand=True).astype(float)\n",
    "\n",
    "# 8.) Convert timestamp และ last_activity เป็น datetime\n",
    "fmt = \"%Y-%m-%d %H:%M:%S.%f%z\"\n",
    "df = safe_parse_datetime(df, 'timestamp', fmt)\n",
    "df = safe_parse_datetime(df, 'last_activity', fmt)\n",
    "\n",
    "# 9.) new Column Solve date\n",
    "df['solve_days'] = (df['last_activity'] - df['timestamp']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9ffe5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[solve_days] mean=73.9108, Q1=1.0000, Q3=71.0000, IQR=70.0000, lower=0.0000, upper=211.0000\n",
      "=== ASCENDING SORT ===\n",
      "        solve_days\n",
      "295920          -1\n",
      "367246          -1\n",
      "410774          -1\n",
      "528415          -1\n",
      "534478          -1\n",
      "...            ...\n",
      "786684           0\n",
      "340              0\n",
      "786715           0\n",
      "786714           0\n",
      "786713           0\n",
      "\n",
      "[300 rows x 1 columns]\n",
      "=== DESCENDING SORT ===\n",
      "       solve_days\n",
      "7            1073\n",
      "61           1046\n",
      "29           1021\n",
      "52           1008\n",
      "96           1006\n",
      "77           1004\n",
      "67            992\n",
      "110           970\n",
      "166           962\n",
      "380           961\n",
      "136           956\n",
      "3260          956\n",
      "832           955\n",
      "879           955\n",
      "1545          954\n",
      "1694          953\n",
      "8624          952\n",
      "8623          952\n",
      "12415         952\n",
      "8622          952\n",
      "count of non-NaN values: 785610\n",
      "number of col over 211.0000:  99586\n",
      "Before eliminating outliers 785610\n",
      "After eliminating outliers 685891\n"
     ]
    }
   ],
   "source": [
    "# 10.1) eliminate outliner : solve_days\n",
    "col = \"solve_days\"\n",
    "\n",
    "mean_val = df[col].mean()\n",
    "Q1 = df[col].quantile(0.25)\n",
    "Q3 = df[col].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = 0\n",
    "upper = Q3 + 2 * IQR\n",
    "print(f\"[{col}] mean={mean_val:.4f}, Q1={Q1:.4f}, Q3={Q3:.4f}, IQR={IQR:.4f}, lower={lower:.4f}, upper={upper:.4f}\")\n",
    "df_asc = df.sort_values(by=col, ascending=True)\n",
    "print(\"=== ASCENDING SORT ===\")\n",
    "print(df_asc[[col]].head(300))   # log 300 rows แรก\n",
    "df_desc = df.sort_values(by=col, ascending=False)\n",
    "print(\"=== DESCENDING SORT ===\")\n",
    "print(df_desc[[col]].head(20))  # log 20 rows แรก\n",
    "print(\"count of non-NaN values:\", df[col].count())\n",
    "print(f\"number of col over {upper:.4f}: \", (df[col] > upper).sum())\n",
    "\n",
    "print(\"Before eliminating outliers\", df[col].count())\n",
    "df = df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "print(\"After eliminating outliers\", df[col].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ef14425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[count_reopen] mean=0.1128, Q1=0.0000, Q3=0.0000, IQR=0.0000, lower=0.0000, upper=2.0000\n",
      "count count_reopen not a 0 & na :  43696 mean not a 0 & na :  1.7699331746612963\n",
      "=== ASCENDING SORT ===\n",
      "     count_reopen\n",
      "49              0\n",
      "55              0\n",
      "56              0\n",
      "70              0\n",
      "80              0\n",
      "..            ...\n",
      "646             0\n",
      "647             0\n",
      "648             0\n",
      "649             0\n",
      "650             0\n",
      "\n",
      "[300 rows x 1 columns]\n",
      "=== DESCENDING SORT ===\n",
      "        count_reopen\n",
      "670683            67\n",
      "624874            65\n",
      "304095            65\n",
      "340128            61\n",
      "247441            59\n",
      "660043            58\n",
      "694861            58\n",
      "659926            57\n",
      "315620            53\n",
      "653762            47\n",
      "346084            45\n",
      "327611            45\n",
      "295728            44\n",
      "272219            43\n",
      "326695            43\n",
      "167540            42\n",
      "287463            41\n",
      "671731            41\n",
      "704230            39\n",
      "345165            39\n",
      "count of non-NaN values: 685891\n",
      "number of col over 2.0000:  6120\n",
      "Before eliminating outliers 685891\n",
      "0 2\n",
      "After eliminating outliers 679771\n"
     ]
    }
   ],
   "source": [
    "# 10.2) eliminate outliner : count_reopen\n",
    "col = \"count_reopen\"\n",
    "\n",
    "mean_val = df[col].mean()\n",
    "Q1 = df[col].quantile(0.25)\n",
    "Q3 = df[col].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = 0\n",
    "upper = 2\n",
    "print(f\"[{col}] mean={mean_val:.4f}, Q1={Q1:.4f}, Q3={Q3:.4f}, IQR={IQR:.4f}, lower={lower:.4f}, upper={upper:.4f}\")\n",
    "print(f\"count {col} not a 0 & na : \", (df[col].ne(0) & df[col].notna()).sum(), f\"mean not a 0 & na : \", (df.loc[df[col].ne(0) & df[col].notna(), col].mean()))\n",
    "\n",
    "df_asc = df.sort_values(by=col, ascending=True)\n",
    "print(\"=== ASCENDING SORT ===\")\n",
    "print(df_asc[[col]].head(300))   # log 300 rows แรก\n",
    "df_desc = df.sort_values(by=col, ascending=False)\n",
    "print(\"=== DESCENDING SORT ===\")\n",
    "print(df_desc[[col]].head(20))  # log 20 rows แรก\n",
    "print(\"count of non-NaN values:\", df[col].count())\n",
    "print(f\"number of col over {upper:.4f}: \", (df[col] > upper).sum())\n",
    "\n",
    "print(\"Before eliminating outliers\", df[col].count())\n",
    "print(lower, upper)\n",
    "df = df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "print(\"After eliminating outliers\", df[col].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2aaf73be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(679771, 22)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "# before : Loaded 787,026 rows × 16 columns\n",
    "# Truncate Outliers after : Loaded 785,610 rows × 23 columns\n",
    "# Remove Outliners after : Loaded 392,070 rows × 23 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d0565a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .csv\n",
    "df.to_csv(\"clean_data.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12236aab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsde-cedt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
