"""
Main Streamlit Dashboard - Urban Issue Forecasting System
Bangkok Traffy Complaint Analysis & Prediction

‡∏£‡∏∞‡∏ö‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÉ‡∏ô‡πÄ‡∏Ç‡∏ï‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£
‡∏£‡∏ß‡∏° ML models: RandomForest Forecaster ‡πÅ‡∏•‡∏∞ Isolation Forest Anomaly Detector

Run: streamlit run visualization/dashboard/main_dashboard.py
"""

import streamlit as st
import pandas as pd
import numpy as np
import folium
from folium.plugins import HeatMap, MarkerCluster
from streamlit_folium import folium_static
from datetime import datetime, timedelta
from pathlib import Path
import sys

# Add current directory to path
sys.path.append(str(Path(__file__).parent))

# Import custom modules
from viz_modules import (
    plot_complaints_by_district,
    plot_complaint_distribution_across_districts,
    plot_top_complaint_districts,
    plot_complaint_heatmap,
    plot_complaint_types_pie,
    plot_resolution_time_by_district,
    plot_time_series_comparison,
    plot_hourly_pattern,
    plot_weekday_pattern,
    plot_state_distribution
)

from ml_integration import (
    MLModelIntegrator,
    plot_forecast_visualization,
    plot_anomaly_scatter,
    plot_anomaly_distribution
)

# Page configuration
st.set_page_config(
    page_title="Urban Issue Dashboard - Bangkok",
    page_icon="üèôÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
    <style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        padding: 1rem 0;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    .sub-header {
        font-size: 1.2rem;
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 10px;
        color: white;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .info-box {
        background-color: rgba(31, 119, 180, 0.1);
        padding: 1rem;
        border-left: 4px solid #1f77b4;
        border-radius: 5px;
        margin: 1rem 0;
        color: inherit;
    }
    .info-box b {
        color: #1f77b4;
    }
    </style>
""", unsafe_allow_html=True)


@st.cache_data(ttl=3600)
def load_data():
    """
    ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• complaint ‡∏à‡∏≤‡∏Å clean_data.csv

    ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡πâ‡∏ß
    ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡πÅ‡∏õ‡∏•‡∏á one-hot encoding ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°
    """
    csv_path = 'clean_data.csv'

    if not Path(csv_path).exists():
        st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {csv_path}")
        st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ß‡∏≤‡∏á clean_data.csv ‡πÑ‡∏ß‡πâ‡πÉ‡∏ô root directory")
        st.stop()

    # Load CSV
    df = pd.read_csv(csv_path)

    st.sidebar.info(f"üìä ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {len(df):,} ‡πÅ‡∏ñ‡∏ß")

    # Parse type field
    def parse_types(type_str):
        if pd.isna(type_str) or type_str == '{}' or type_str == '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏':
            return ['Unknown']
        type_str = str(type_str).strip('{}')
        types = [t.strip() for t in type_str.split(',') if t.strip()]
        return types if types else ['Unknown']

    df['types_list'] = df['type'].apply(parse_types)
    df['primary_type'] = df['types_list'].apply(lambda x: x[0])

    # Convert timestamp
    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')

    # Reconstruct state from one-hot encoding
    def get_state(row):
        if 'state_‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô' in row and row.get('state_‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô', 0) == 1.0:
            return '‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô'
        elif 'state_‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£' in row and row.get('state_‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£', 0) == 1.0:
            return '‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£'
        elif 'state_‡∏£‡∏≠‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á' in row and row.get('state_‡∏£‡∏≠‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á', 0) == 1.0:
            return '‡∏£‡∏≠‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á'
        return 'Unknown'

    df['state'] = df.apply(get_state, axis=1)

    # Reconstruct star rating from one-hot encoding
    def get_star(row):
        star_cols = ['star_1.0', 'star_2.0', 'star_3.0', 'star_4.0', 'star_5.0']
        for i, col in enumerate(star_cols, 1):
            if col in row and row[col] == 1.0:
                return float(i)
        return np.nan

    df['star_rating'] = df.apply(get_star, axis=1)

    # Extract time components
    df['year'] = df['timestamp'].dt.year
    df['month'] = df['timestamp'].dt.month
    df['day_of_week'] = df['timestamp'].dt.dayofweek
    df['hour'] = df['timestamp'].dt.hour

    # Drop rows with missing critical data
    df = df.dropna(subset=['lat', 'lon', 'timestamp'])

    return df


@st.cache_resource
def load_ml_models():
    """
    ‡πÇ‡∏´‡∏•‡∏î ML models ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

    ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• RandomForest ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå
    ‡πÅ‡∏•‡∏∞ Isolation Forest ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥
    """
    integrator = MLModelIntegrator()

    # Load forecasting model
    rf_loaded = integrator.load_forecasting_model()

    # Load anomaly detection model
    anomaly_loaded = integrator.load_anomaly_model()

    status_msg = []
    if rf_loaded:
        status_msg.append("‚úÖ RandomForest Forecaster")
    else:
        status_msg.append("‚ö†Ô∏è RandomForest (‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á)")

    if anomaly_loaded:
        status_msg.append("‚úÖ Isolation Forest Anomaly Detector")
    else:
        status_msg.append("‚ö†Ô∏è Anomaly Detector (‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏≤‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥)")

    st.sidebar.info("ü§ñ ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ ML Models:\n" + "\n".join(status_msg))

    return integrator


def create_geospatial_map(df, map_type='heatmap'):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á complaint

    ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á complaint ‡∏ö‡∏ô‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û
    - Heatmap: ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ô‡∏≤‡πÅ‡∏ô‡πà‡∏ô‡∏Ç‡∏≠‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤
    - Clusters: ‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏∏‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞ complaint ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
    """
    center_lat, center_lon = 13.7563, 100.5018

    m = folium.Map(
        location=[center_lat, center_lon],
        zoom_start=11,
        tiles='OpenStreetMap'
    )

    if map_type == 'heatmap':
        heat_data = [[row['lat'], row['lon']] for idx, row in df.head(10000).iterrows()]
        HeatMap(heat_data, radius=15, blur=25, max_zoom=13).add_to(m)

    elif map_type == 'clusters':
        marker_cluster = MarkerCluster().add_to(m)

        for idx, row in df.head(1000).iterrows():
            folium.Marker(
                location=[row['lat'], row['lon']],
                popup=f"""
                    <b>‡πÄ‡∏Ç‡∏ï:</b> {row['district']}<br>
                    <b>‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó:</b> {row['primary_type']}<br>
                    <b>‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:</b> {row['timestamp'].strftime('%Y-%m-%d')}<br>
                    <b>‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞:</b> {row['state']}<br>
                    <b>‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏Å‡πâ:</b> {row['solve_days']} ‡∏ß‡∏±‡∏ô
                """,
                icon=folium.Icon(color='blue', icon='info-sign')
            ).add_to(marker_cluster)

    return m


def main():
    """Main dashboard application"""

    # Header
    st.markdown('<div class="main-header">üèôÔ∏è Urban Issue Forecasting Dashboard</div>',
               unsafe_allow_html=True)
    st.markdown('<div class="sub-header">‡∏£‡∏∞‡∏ö‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏Ç‡∏ï‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£ | Bangkok Traffy Data Analysis</div>',
               unsafe_allow_html=True)
    st.markdown("---")

    # Load data and models
    with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ ML models..."):
        df = load_data()
        ml_integrator = load_ml_models()

    # Sidebar filters
    st.sidebar.header("üéõÔ∏è ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á (Filters)")

    # Date range filter
    min_date = df['timestamp'].min().date()
    max_date = df['timestamp'].max().date()

    date_range = st.sidebar.date_input(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤",
        value=(min_date, max_date),
        min_value=min_date,
        max_value=max_date
    )

    # District filter
    districts = ['All'] + sorted(df['district'].dropna().unique().tolist())
    selected_district = st.sidebar.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏Ç‡∏ï", districts)

    # Complaint type filter
    types = ['All'] + sorted(df['primary_type'].unique().tolist())
    selected_type = st.sidebar.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó Complaint", types)

    # Map visualization type
    map_type = st.sidebar.radio(
        "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà",
        ['heatmap', 'clusters'],
        format_func=lambda x: 'Heat Map (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ô‡∏≤‡πÅ‡∏ô‡πà‡∏ô)' if x == 'heatmap' else 'Marker Clusters (‡∏à‡∏∏‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)'
    )

    # Apply filters
    df_filtered = df.copy()
    if len(date_range) == 2:
        df_filtered = df_filtered[
            (df_filtered['timestamp'].dt.date >= date_range[0]) &
            (df_filtered['timestamp'].dt.date <= date_range[1])
        ]

    if selected_district != 'All':
        df_filtered = df_filtered[df_filtered['district'] == selected_district]

    if selected_type != 'All':
        df_filtered = df_filtered[df_filtered['primary_type'] == selected_type]

    # Key Metrics
    st.header("üìä ‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î‡∏´‡∏•‡∏±‡∏Å (Key Metrics)")

    col1, col2, col3, col4, col5 = st.columns(5)

    with col1:
        st.metric(
            "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Complaint ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î",
            f"{len(df_filtered):,}",
            delta=f"{len(df_filtered) - len(df):.0f}" if selected_district != 'All' or selected_type != 'All' else None
        )

    with col2:
        avg_resolution = df_filtered['solve_days'].mean()
        st.metric(
            "‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢",
            f"{avg_resolution:.1f} ‡∏ß‡∏±‡∏ô"
        )

    with col3:
        completion_rate = (df_filtered['state'] == '‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô').mean() * 100
        st.metric(
            "‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô",
            f"{completion_rate:.1f}%"
        )

    with col4:
        unique_districts = df_filtered['district'].nunique()
        st.metric(
            "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ç‡∏ï",
            f"{unique_districts}"
        )

    with col5:
        unique_types = df_filtered['primary_type'].nunique()
        st.metric(
            "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤",
            f"{unique_types}"
        )

    st.markdown("---")

    # Main tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üó∫Ô∏è ‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡∏†‡∏π‡∏°‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå",
        "üìä ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏Ç‡∏ï‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó",
        "ü§ñ ML: ‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå",
        "‚ö†Ô∏è ML: ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥",
        "üìà ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°"
    ])

    # Tab 1: Geospatial Analysis
    with tab1:
        st.header("üó∫Ô∏è ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà")

        st.markdown("""
        <div class="info-box">
        <b>‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:</b> ‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á complaint ‡πÉ‡∏ô‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£<br>
        - <b>Heat Map:</b> ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ô‡∏≤‡πÅ‡∏ô‡πà‡∏ô‡∏Ç‡∏≠‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà<br>
        - <b>Marker Clusters:</b> ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ complaint
        </div>
        """, unsafe_allow_html=True)

        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà..."):
            m = create_geospatial_map(df_filtered, map_type=map_type)
            folium_static(m, width=1400, height=600)

        # District statistics table
        st.subheader("üìã ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏Ç‡∏ï")
        district_stats = df_filtered.groupby('district').agg({
            'lat': 'count',
            'solve_days': 'mean',
        }).round(2)
        district_stats.columns = ['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Complaint', '‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ (‡∏ß‡∏±‡∏ô)']
        district_stats = district_stats.sort_values('‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Complaint', ascending=False)

        st.dataframe(district_stats, use_container_width=True, height=400)

    # Tab 2: District and Type Analysis
    with tab2:
        st.header("üìä ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏Ç‡∏ï‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó Complaint")

        # Top districts
        st.subheader("üèÜ ‡πÄ‡∏Ç‡∏ï‡∏ó‡∏µ‡πà‡∏°‡∏µ Complaint ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î")
        st.markdown("""
        <div class="info-box">
        <b>‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:</b> ‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÄ‡∏Ç‡∏ï‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô complaint ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ‡∏ä‡πà‡∏ß‡∏¢‡∏£‡∏∞‡∏ö‡∏∏‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏¥‡πÄ‡∏®‡∏©
        </div>
        """, unsafe_allow_html=True)

        top_n = st.slider("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ç‡∏ï‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á", 5, 30, 15, key="top_districts")
        st.plotly_chart(plot_top_complaint_districts(df_filtered, top_n), use_container_width=True)

        st.markdown("---")

        # Complaints by district
        st.subheader("üìç ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏Ç‡∏ï‡∏°‡∏µ Complaint ‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà")
        st.markdown("""
        <div class="info-box">
        <b>‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:</b> ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á complaint ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏Ç‡∏ï
        ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏Ç‡∏ï‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÉ‡∏î‡∏ö‡πâ‡∏≤‡∏á
        </div>
        """, unsafe_allow_html=True)

        col_filter1, col_spacer1 = st.columns([2, 3])
        with col_filter1:
            complaint_filter_1 = st.selectbox(
                "‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó Complaint",
                ['All'] + sorted(df_filtered['primary_type'].unique().tolist()),
                key="complaint_by_district"
            )

        st.plotly_chart(plot_complaints_by_district(df_filtered, complaint_filter_1), use_container_width=True)

        st.markdown("---")

        # Complaint distribution across districts
        st.subheader("üóÇÔ∏è ‡πÅ‡∏ï‡πà‡∏•‡∏∞ Complaint ‡∏°‡∏µ‡πÉ‡∏ô‡πÄ‡∏Ç‡∏ï‡πÑ‡∏´‡∏ô‡∏ö‡πâ‡∏≤‡∏á ‡πÄ‡∏Ç‡∏ï‡∏•‡∏∞‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà")
        st.markdown("""
        <div class="info-box">
        <b>‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:</b> ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤ complaint ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô‡πÄ‡∏Ç‡∏ï‡πÉ‡∏î‡∏ö‡πâ‡∏≤‡∏á
        ‡∏ä‡πà‡∏ß‡∏¢‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
        </div>
        """, unsafe_allow_html=True)

        col_filter2, col_spacer2 = st.columns([2, 3])
        with col_filter2:
            district_filter_1 = st.selectbox(
                "‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏Ç‡∏ï",
                ['All'] + sorted(df_filtered['district'].dropna().unique().tolist()),
                key="complaint_distribution"
            )

        st.plotly_chart(plot_complaint_distribution_across_districts(df_filtered, district_filter_1), use_container_width=True)

        st.markdown("---")

        # Additional visualizations
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("ü•ß ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó Complaint")
            st.plotly_chart(plot_complaint_types_pie(df_filtered), use_container_width=True)

        with col2:
            st.subheader("üìä ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£")
            st.plotly_chart(plot_state_distribution(df_filtered), use_container_width=True)

        # Heatmap
        st.subheader("üî• Heatmap: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡∏≠‡∏á Complaint ‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤")
        st.markdown("""
        <div class="info-box">
        <b>‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:</b> ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏Ç‡∏≠‡∏á complaint ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏Ç‡∏ï‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤
        ‡∏ä‡πà‡∏ß‡∏¢‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡∏≤‡∏°‡∏§‡∏î‡∏π‡∏Å‡∏≤‡∏•‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏°‡∏≤‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏¥‡πÄ‡∏®‡∏©
        </div>
        """, unsafe_allow_html=True)
        st.plotly_chart(plot_complaint_heatmap(df_filtered), use_container_width=True)

        # Resolution time
        st.subheader("‚è±Ô∏è ‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏Ç‡∏ï")
        st.markdown("""
        <div class="info-box">
        <b>‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:</b> ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏Ç‡∏ï
        ‡∏ä‡πà‡∏ß‡∏¢‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏Ç‡∏ï‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤
        </div>
        """, unsafe_allow_html=True)
        st.plotly_chart(plot_resolution_time_by_district(df_filtered), use_container_width=True)

    # Tab 3: Forecasting
    with tab3:
        st.header("ü§ñ ‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏î‡πâ‡∏ß‡∏¢ Machine Learning")

        st.markdown("""
        <div class="info-box">
        <b>‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:</b> ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• RandomForest ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏à‡∏≥‡∏ô‡∏ß‡∏ô complaint ‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï<br>
        - <b>‡πÄ‡∏™‡πâ‡∏ô‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô:</b> ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡∏≠‡∏î‡∏µ‡∏ï<br>
        - <b>‡πÄ‡∏™‡πâ‡∏ô‡∏™‡∏µ‡πÅ‡∏î‡∏á:</b> ‡∏Ñ‡πà‡∏≤‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå<br>
        - <b>‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏µ‡πÄ‡∏ó‡∏≤:</b> ‡∏ä‡πà‡∏ß‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô (Confidence Interval)
        </div>
        """, unsafe_allow_html=True)

        forecast_days = st.slider("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå", 7, 60, 30)

        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå..."):
            forecast_df = ml_integrator.generate_forecast(df_filtered, days_ahead=forecast_days)

        st.plotly_chart(plot_forecast_visualization(forecast_df, df_filtered), use_container_width=True)

        # Forecast statistics
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric(
                "‡∏Ñ‡πà‡∏≤‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢",
                f"{forecast_df['predicted'].mean():.0f} complaints/‡∏ß‡∏±‡∏ô"
            )

        with col2:
            st.metric(
                "‡∏Ñ‡πà‡∏≤‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î",
                f"{forecast_df['predicted'].max():.0f} complaints"
            )

        with col3:
            st.metric(
                "‡∏Ñ‡πà‡∏≤‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î",
                f"{forecast_df['predicted'].min():.0f} complaints"
            )

        # Show forecast data
        with st.expander("üìã ‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á"):
            forecast_display = forecast_df.copy()
            forecast_display['date'] = forecast_display['date'].dt.strftime('%Y-%m-%d')
            forecast_display.columns = ['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', '‡∏Ñ‡πà‡∏≤‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå', '‡∏Ç‡∏≠‡∏ö‡∏•‡πà‡∏≤‡∏á', '‡∏Ç‡∏≠‡∏ö‡∏ö‡∏ô']
            st.dataframe(forecast_display, use_container_width=True, height=400)

    # Tab 4: Anomaly Detection
    with tab4:
        st.header("‚ö†Ô∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡∏î‡πâ‡∏ß‡∏¢ Machine Learning")

        st.markdown("""
        <div class="info-box">
        <b>‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:</b> ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• Isolation Forest ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö complaint ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥<br>
        ‡πÄ‡∏ä‡πà‡∏ô ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ô‡∏≤‡∏ô‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥ ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Å‡∏¥‡∏î‡πÉ‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà/‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏õ‡∏Å‡∏ï‡∏¥<br>
        Anomaly Score ‡∏™‡∏π‡∏á = ‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡∏°‡∏≤‡∏Å
        </div>
        """, unsafe_allow_html=True)

        # Sample data for performance with user control
        st.markdown("##### ‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")

        col_setting1, col_setting2 = st.columns([2, 3])
        with col_setting1:
            total_data = len(df_filtered)

            # Use percentage-based slider
            if total_data <= 10000:
                default_pct = 100  # Use all data if small dataset
            elif total_data <= 100000:
                default_pct = 50  # 50% for medium dataset
            else:
                default_pct = 10  # 10% for large dataset (e.g., 78k rows from 780k)

            sample_percentage = st.slider(
                "‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå",
                min_value=1,
                max_value=100,
                value=default_pct,
                step=1,
                format="%d%%",
                help="‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå‡∏™‡∏π‡∏á = ‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏∂‡πâ‡∏ô ‡πÅ‡∏ï‡πà‡∏ä‡πâ‡∏≤‡∏Ç‡∏∂‡πâ‡∏ô | ‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå‡∏ï‡πà‡∏≥ = ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô ‡πÅ‡∏ï‡πà‡∏≠‡∏≤‡∏à‡∏û‡∏•‡∏≤‡∏î‡∏ö‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"
            )

            # Calculate actual sample size
            sample_size = int(total_data * sample_percentage / 100)

            # Ensure minimum sample size
            sample_size = max(min(5000, total_data), sample_size)

        with col_setting2:
            st.info(f"üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå {sample_size:,} ‡∏à‡∏≤‡∏Å {total_data:,} ‡πÅ‡∏ñ‡∏ß ({sample_percentage}%)")

        # Sample data
        df_for_anomaly = df_filtered.copy()
        sampled = False
        if len(df_filtered) > sample_size:
            df_for_anomaly = df_filtered.sample(n=sample_size, random_state=42).copy()
            sampled = True

        @st.cache_data(ttl=3600, show_spinner=False)
        def detect_anomalies_cached(_ml_int, data_hash, size):
            return _ml_int.detect_anomalies(df_for_anomaly)

        # Progress indicator
        progress_text = "‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•..."
        progress_bar = st.progress(0, text=progress_text)

        try:
            progress_bar.progress(20, text="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏Å‡∏±‡∏î features...")
            data_hash = hash(str(len(df_for_anomaly)) + str(sample_size))

            progress_bar.progress(40, text="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ ML model...")
            df_with_anomalies = detect_anomalies_cached(ml_integrator, data_hash, sample_size)

            progress_bar.progress(100, text="‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
            progress_bar.empty()
        except Exception as e:
            progress_bar.empty()
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")
            st.stop()

        # Anomaly statistics
        total_anomalies = df_with_anomalies['is_anomaly'].sum()
        anomaly_rate = (total_anomalies / len(df_with_anomalies)) * 100

        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric(
                "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Anomalies ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö",
                f"{total_anomalies:,}"
            )

        with col2:
            st.metric(
                "‡∏≠‡∏±‡∏ï‡∏£‡∏≤ Anomaly",
                f"{anomaly_rate:.2f}%"
            )

        with col3:
            avg_anomaly_score = df_with_anomalies[df_with_anomalies['is_anomaly'] == 1]['anomaly_score'].mean()
            st.metric(
                "Anomaly Score ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢",
                f"{avg_anomaly_score:.2f}"
            )

        # Anomaly scatter plot
        st.subheader("üìà Anomaly Detection Timeline")
        st.plotly_chart(plot_anomaly_scatter(df_with_anomalies), use_container_width=True)

        # Anomaly distribution
        st.subheader("üìä ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á Anomalies")
        st.plotly_chart(plot_anomaly_distribution(df_with_anomalies), use_container_width=True)

        # Anomaly table
        st.subheader("üìã ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Anomalies ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö (Top 50)")
        anomalies = df_with_anomalies[df_with_anomalies['is_anomaly'] == 1].copy()
        anomalies_display = anomalies[['timestamp', 'district', 'primary_type', 'solve_days', 'anomaly_score']].sort_values(
            'anomaly_score', ascending=False
        ).head(50)

        anomalies_display.columns = ['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', '‡πÄ‡∏Ç‡∏ï', '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó', '‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏Å‡πâ (‡∏ß‡∏±‡∏ô)', 'Anomaly Score']
        st.dataframe(anomalies_display, use_container_width=True, height=400)

    # Tab 5: Additional Analytics
    with tab5:
        st.header("üìà ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°")

        # Time patterns
        st.subheader("‚è∞ ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô‡∏ß‡∏±‡∏ô**")
            st.plotly_chart(plot_hourly_pattern(df_filtered), use_container_width=True)

        with col2:
            st.markdown("**‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡πÉ‡∏ô‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå**")
            st.plotly_chart(plot_weekday_pattern(df_filtered), use_container_width=True)

        # Time series comparison
        st.subheader("üìâ ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏Ç‡∏ï")
        st.markdown("""
        <div class="info-box">
        <b>‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:</b> ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô complaint ‡∏Ç‡∏≠‡∏á‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏Ç‡∏ï‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤
        </div>
        """, unsafe_allow_html=True)

        top_districts_for_comparison = df_filtered['district'].value_counts().head(10).index.tolist()
        selected_districts = st.multiselect(
            "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏Ç‡∏ï‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö",
            top_districts_for_comparison,
            default=top_districts_for_comparison[:5]
        )

        if selected_districts:
            st.plotly_chart(plot_time_series_comparison(df_filtered, selected_districts), use_container_width=True)

        # Summary statistics
        st.subheader("üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏™‡∏£‡∏∏‡∏õ")

        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("**Top 5 ‡πÄ‡∏Ç‡∏ï‡∏ó‡∏µ‡πà‡∏°‡∏µ Complaint ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î**")
            top_districts = df_filtered['district'].value_counts().head(5)
            for district, count in top_districts.items():
                st.write(f"- {district}: {count:,}")

        with col2:
            st.markdown("**Top 5 ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó Complaint**")
            top_types = df_filtered['primary_type'].value_counts().head(5)
            for ptype, count in top_types.items():
                st.write(f"- {ptype}: {count:,}")

        with col3:
            st.markdown("**‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤**")
            st.write(f"- ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {df_filtered['solve_days'].mean():.1f} ‡∏ß‡∏±‡∏ô")
            st.write(f"- ‡∏°‡∏±‡∏ò‡∏¢‡∏ê‡∏≤‡∏ô: {df_filtered['solve_days'].median():.1f} ‡∏ß‡∏±‡∏ô")
            st.write(f"- ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: {df_filtered['solve_days'].max():.0f} ‡∏ß‡∏±‡∏ô")
            st.write(f"- ‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î: {df_filtered['solve_days'].min():.0f} ‡∏ß‡∏±‡∏ô")

    # Footer
    st.markdown("---")
    st.markdown(f"""
        <div style='text-align: center; color: #666; padding: 2rem;'>
            <p style='font-size: 1.2rem; font-weight: bold;'>üèôÔ∏è Urban Issue Forecasting System</p>
            <p>DSDE M150-Lover Team | Chulalongkorn University</p>
            <p>Data Source: Bangkok Traffy Fondue | Data Rows: {len(df):,}</p>
            <p>ML Models: RandomForest Forecaster + Isolation Forest Anomaly Detector</p>
            <p>Last Updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
